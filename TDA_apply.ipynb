{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORdg4sTPgmFNgfAFJ3DbNw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raghayev17889/tda_project/blob/main/TDA_apply.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trials:\n",
        "I have tried numbers like 0 vs 8 and 8 vs 6 and 1 vs 8\n",
        "\n",
        "*   0 vs 8  -- I mean not bad nearly near to raw data\n",
        "*   8 vs 6  -- very bad in simpler one(first, but normal(~89) in others) worse than raw data\n",
        "*   1 vs 8 -- nearly perfect(even got 1.0 in one) I hope it is not overfitting :) and better than raw data"
      ],
      "metadata": {
        "id": "b_0vJ2eYaNpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ripser\n",
        "!pip install persim\n",
        "!pip install gudhi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUgrrrCOY_lD",
        "outputId": "0f9f2f57-16ca-4668-c5d8-36e8b0f013dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ripser\n",
            "  Downloading ripser-0.6.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.11/dist-packages (from ripser) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ripser) (2.0.2)\n",
            "Collecting persim (from ripser)\n",
            "  Downloading persim-0.3.8-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ripser) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from ripser) (1.6.1)\n",
            "Collecting deprecated (from persim->ripser)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting hopcroftkarp (from persim->ripser)\n",
            "  Downloading hopcroftkarp-1.2.5.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from persim->ripser) (1.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from persim->ripser) (3.10.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->ripser) (3.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->persim->ripser) (1.17.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim->ripser) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim->ripser) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim->ripser) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim->ripser) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim->ripser) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim->ripser) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim->ripser) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim->ripser) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->persim->ripser) (1.17.0)\n",
            "Downloading ripser-0.6.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (841 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.3/841.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading persim-0.3.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: hopcroftkarp\n",
            "  Building wheel for hopcroftkarp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hopcroftkarp: filename=hopcroftkarp-1.2.5-py2.py3-none-any.whl size=18104 sha256=4da39dc5612a6b082ec769836bc94f18de0c35d3fca6e2b81e075d5faf23b61d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/cc/2d/de23a8b9ae586817b0b44de4a4b1a08f23473e248a644b312f\n",
            "Successfully built hopcroftkarp\n",
            "Installing collected packages: hopcroftkarp, deprecated, persim, ripser\n",
            "Successfully installed deprecated-1.2.18 hopcroftkarp-1.2.5 persim-0.3.8 ripser-0.6.12\n",
            "Requirement already satisfied: persim in /usr/local/lib/python3.11/dist-packages (0.3.8)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from persim) (1.2.18)\n",
            "Requirement already satisfied: hopcroftkarp in /usr/local/lib/python3.11/dist-packages (from persim) (1.2.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from persim) (1.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from persim) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from persim) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from persim) (1.6.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->persim) (1.17.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->persim) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->persim) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->persim) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->persim) (1.17.0)\n",
            "Collecting gudhi\n",
            "  Downloading gudhi-3.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from gudhi) (2.0.2)\n",
            "Downloading gudhi-3.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gudhi\n",
            "Successfully installed gudhi-3.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2PrFboUGa0ml"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
        "y = y.astype(int)\n",
        "\n",
        "# Filter the wanted data\n",
        "mask = (y == 0) | (y == 8)\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "#reducing the samples because it took too much time\n",
        "X_training = X[:3000, :]\n",
        "y_training = y[:3000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gpt\n",
        "# Normalize pixel values to [0, 1]\n",
        "X_training = X_training / 255.0\n",
        "\n",
        "# Reshape to 28x28 images for each sample\n",
        "X_imgs = X_training.reshape(-1, 28, 28)\n"
      ],
      "metadata": {
        "id": "6Z1Zwifda72d"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gpt\n",
        "def image_to_pointcloud(img, threshold=0.5):\n",
        "    points = np.argwhere(img > threshold)\n",
        "    return points\n",
        "\n",
        "pointclouds = [image_to_pointcloud(img) for img in X_imgs]\n"
      ],
      "metadata": {
        "id": "Oc31ylbca-Ce"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ripser import ripser\n",
        "from persim import PersistenceImager\n",
        "\n",
        "diagrams = [ripser(pc, maxdim=1)['dgms'] for pc in pointclouds]\n"
      ],
      "metadata": {
        "id": "NjGC8PHxa_hM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tda_features(diag):\n",
        "    H1 = diag[1]\n",
        "    if len(H1) == 0:\n",
        "        return [0, 0]  # no loops\n",
        "    lifetimes = H1[:,1] - H1[:,0]\n",
        "    lifetimes = np.sort(lifetimes)\n",
        "    n_of_loops = len(H1)\n",
        "    longest_loop = 0\n",
        "    second_longest = 0\n",
        "    if(n_of_loops > 0):\n",
        "      longest_loop = lifetimes[-1]\n",
        "    if(n_of_loops > 1):\n",
        "      second_longest = lifetimes[-2]\n",
        "    return [\n",
        "        n_of_loops,\n",
        "        longest_loop\n",
        "    ]\n",
        "\n",
        "tda_features = np.array([extract_tda_features(dgm) for dgm in diagrams])\n"
      ],
      "metadata": {
        "id": "IbWyN-N-dJxD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tda_features, y_training, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "X_unseen = X[3000:5000]\n",
        "y_unseen = y[3000:5000]\n",
        "\n",
        "# Reshape and convert to point clouds\n",
        "X_unseen_imgs = X_unseen.reshape(-1, 28, 28)\n",
        "pointclouds_unseen = [image_to_pointcloud(img) for img in X_unseen_imgs]\n",
        "diagrams_unseen = [ripser(pc, maxdim=1)['dgms'] for pc in pointclouds_unseen]\n",
        "tda_features_unseen = np.array([extract_tda_features(dgm) for dgm in diagrams_unseen])\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_unseen = clf.predict(tda_features_unseen)\n",
        "print(\"Unseen Accuracy (on samples 3000–5000):\", accuracy_score(y_unseen, y_pred_unseen))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtJxjTTneFSp",
        "outputId": "0ae50def-9d42-4c89-eed4-2052a3f60a72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets add a new feature\n",
        "def extract_tda_features(diag):\n",
        "    H1 = diag[1]\n",
        "    if len(H1) == 0:\n",
        "        return [0, 0]  # no loops\n",
        "    lifetimes = H1[:,1] - H1[:,0]\n",
        "    lifetimes = np.sort(lifetimes)\n",
        "    n_of_loops = len(H1)\n",
        "    longest_loop = 0\n",
        "    second_longest = 0\n",
        "    if(n_of_loops > 0):\n",
        "      longest_loop = lifetimes[-1]\n",
        "    if(n_of_loops > 1):\n",
        "      second_longest = lifetimes[-2]\n",
        "    return [\n",
        "        n_of_loops,\n",
        "        longest_loop,\n",
        "        second_longest\n",
        "    ]\n",
        "\n",
        "tda_features = np.array([extract_tda_features(dgm) for dgm in diagrams])\n"
      ],
      "metadata": {
        "id": "rkbCGJhoa_y7"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tda_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNf4FnojbCgD",
        "outputId": "ce61f2fd-6661-4c3e-ba01-056e974e9dd0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets add a new feature\n",
        "def extract_tda_features(diag):\n",
        "    H1 = diag[1]\n",
        "    if len(H1) == 0:\n",
        "        return [0, 0]  # no loops\n",
        "    lifetimes = np.stack((H1[:,1] - H1[:,0], H1[:,1]), axis=1)\n",
        "    lifetimes = lifetimes[np.argsort(lifetimes[:, 0])]\n",
        "    n_of_loops = len(H1)\n",
        "    longest_loop = 0\n",
        "    second_longest = 0\n",
        "    death_of_longest = 0\n",
        "    if(n_of_loops > 0):\n",
        "      longest_loop = lifetimes[-1][0]\n",
        "      death_of_longest = lifetimes[-1][1]\n",
        "    if(n_of_loops > 1):\n",
        "      second_longest = lifetimes[-2][0]\n",
        "    return [\n",
        "        n_of_loops,\n",
        "        longest_loop,\n",
        "        second_longest,\n",
        "        death_of_longest\n",
        "    ]\n",
        "\n",
        "tda_features = np.array([extract_tda_features(dgm) for dgm in diagrams])\n"
      ],
      "metadata": {
        "id": "t452aGJCekJO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tda_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8w20draf7n4",
        "outputId": "6c6fd3d8-b75e-4619-f758-3978011bce08"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's add a new feature\n",
        "def extract_tda_features(diag):\n",
        "    H1 = diag[1]\n",
        "    if len(H1) == 0:\n",
        "        return [0, 0, 0, 0, 0, 0, 0]\n",
        "    lifetimes = np.stack((H1[:, 1] - H1[:, 0], H1[:, 0], H1[:, 1]), axis=1)\n",
        "    lifetimes = lifetimes[np.argsort(lifetimes[:, 0])]\n",
        "\n",
        "    n_of_loops = len(H1)\n",
        "    longest_loop = 0\n",
        "    second_longest = 0\n",
        "    death_of_longest = 0\n",
        "    death_of_second = 0\n",
        "    birth_of_longest = 0\n",
        "    birth_of_second = 0\n",
        "\n",
        "    if n_of_loops > 0:\n",
        "        longest_loop = lifetimes[-1][0]\n",
        "        birth_of_longest = lifetimes[-1][1]\n",
        "        death_of_longest = lifetimes[-1][2]\n",
        "\n",
        "    if n_of_loops > 1:\n",
        "        second_longest = lifetimes[-2][0]\n",
        "        birth_of_second = lifetimes[-2][1]\n",
        "        death_of_second = lifetimes[-2][2]\n",
        "\n",
        "    return [\n",
        "        n_of_loops,\n",
        "        longest_loop,\n",
        "        second_longest,\n",
        "        birth_of_longest,\n",
        "        birth_of_second,\n",
        "        death_of_longest,\n",
        "        death_of_second\n",
        "    ]\n",
        "\n",
        "tda_features = np.array([extract_tda_features(dgm) for dgm in diagrams])\n"
      ],
      "metadata": {
        "id": "yDeRl-5YlLbs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tda_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xV0EodVljHl",
        "outputId": "e1052783-82a4-4a1c-ab20-2d2d8fd579ae"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt version\n",
        "from persim import PersistenceImager\n",
        "\n",
        "pimgr = PersistenceImager(pixel_size=0.1)\n",
        "\n",
        "\n",
        "h1_diagrams = [dgm[1] for dgm in diagrams]\n",
        "\n",
        "pimgr.fit(h1_diagrams)\n",
        "\n",
        "tda_features_pi = np.array([pimgr.transform(dgm).flatten() for dgm in h1_diagrams])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tda_features_pi, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(max_iter=2000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Improved TDA Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3fEqDUhbii0",
        "outputId": "ee23d7fb-c1be-4f99-a8cd-45f7542ddc1f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved TDA Accuracy: 0.925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf2 = LogisticRegression(max_iter=1000)\n",
        "clf2.fit(X_train2, y_train2)\n",
        "y_pred2 = clf2.predict(X_test2)\n",
        "print(\"Raw pixel accuracy:\", accuracy_score(y_test2, y_pred2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaMQu7y4eFw1",
        "outputId": "ff3dbd28-4c51-4f57-d06d-3c53315d21e8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw pixel accuracy: 0.985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bk7nowFqeMh9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Maalesef Raw data 1 - 0 TDA\n",
        "\n",
        "ama yine de iyi ilerledi :'(\n",
        "\n",
        "###OOOOOOOOO bir yerde yenebildik\n"
      ],
      "metadata": {
        "id": "Q8mBAAb0hUY2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wv2WDjDihZRQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}